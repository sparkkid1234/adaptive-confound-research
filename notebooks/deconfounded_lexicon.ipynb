{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/virgile/.conda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/virgile/.conda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from importlib import reload\n",
    "import adaptive_confound.utils as acu\n",
    "import adaptive_confound.control as acc\n",
    "import adaptive_confound.topic_model as actm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import itertools as it\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from copy import deepcopy\n",
    "from scipy.stats import mode\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input, Lambda, Concatenate, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.datasets import reuters\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "import keras.utils.vis_utils as kvu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystr = 'location'\n",
    "zstr = 'gender'\n",
    "twitter = acu.read_pickle(\"/data/virgile/confound/adaptive/in/twitter_dataset_y={}_z={}.pkl\".format(ystr, zstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(d, seed=1234):\n",
    "    idx = np.arange(d.get_size())\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(idx)\n",
    "    d.X = d.X[idx]\n",
    "    d.y = d.y[idx]\n",
    "    d.z = d.z[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_dataset(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< Dataset: size=6000, p(y)=0.50, p(z)=0.50, bias=0.50, parent=None >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "twitter.create_biased_datasets(1000, np.linspace(.1,.9,9), k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        y_pred = self.model.predict(self.validation_data[0])[0].argmax(axis=1)\n",
    "        y_true = self.validation_data[1].argmax(axis=1)\n",
    "        z_pred = self.model.predict(self.validation_data[0])[1].argmax(axis=1)\n",
    "        z_true = self.validation_data[2].argmax(axis=1)\n",
    "        \n",
    "        self.f1_y = f1_score(y_true, y_pred)\n",
    "        self.f1_z = f1_score(z_true, z_pred)\n",
    "        \n",
    "        print()\n",
    "        print(\"val_f1_y: {:.4f}\".format(self.f1_y))\n",
    "        print(\"val_f1_z: {:.4f}\".format(self.f1_z), \"z_pred: #1: {:d} / count: {:d}\".format(z_pred.sum(), z_pred.size))\n",
    "        \n",
    "        return\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DR_BOW:\n",
    "    def __init__(self, x_dim, c_dim, xl=100, cl=20, pl=20):\n",
    "        self.x_dim = x_dim\n",
    "        self.c_dim = c_dim\n",
    "        self.xl = xl\n",
    "        self.cl = cl\n",
    "        self.pl = pl\n",
    "        \n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Model predicting Y from C\n",
    "        c_input = Input(shape=(self.c_dim,), name=\"c_input\")\n",
    "        l = Dense(self.cl, activation=\"relu\")(c_input)\n",
    "        y_hat_prime = Dense(2, activation=\"softmax\", name=\"y_hat_prime\")(l)\n",
    "        c2y = Model(c_input, y_hat_prime)\n",
    "\n",
    "        # Reduce dimension of text input\n",
    "        x_input = Input(shape=(self.x_dim,), name=\"x_input\")\n",
    "        e = Dense(self.xl, activation=\"relu\", name=\"e\")(x_input)\n",
    "        \n",
    "        # Concatenate latent representation of text input and prediction of y | c\n",
    "        l = Concatenate()([e, y_hat_prime])\n",
    "        l = Dense(self.pl, activation=\"relu\")(l)\n",
    "        y_hat = Dense(2, activation=\"softmax\", name=\"y_hat\")(l)\n",
    "        self.model = Model([x_input, c_input], [y_hat_prime, y_hat])\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "        \n",
    "    def fit(self, d, *args, **kwargs):\n",
    "        tocat = lambda x: to_categorical(x, num_classes=2)\n",
    "        z = d.z.reshape(-1,1)\n",
    "        return self.model.fit([d.X, z], [tocat(d.y), tocat(d.y)], *args, **kwargs)\n",
    "    \n",
    "    def predict(self, d, *args, **kwargs):\n",
    "        return self.model.predict([d.X, d.z])[1].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DR_BOW(twitter.features.size, 1)\n",
    "kvu.plot_model(m.model, 'DRBOW.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "3000/3000 [==============================] - 2s 550us/step - loss: 0.7037 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0110 - val_loss: 1.3247 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.6293\n",
      "Epoch 2/100\n",
      "3000/3000 [==============================] - 2s 560us/step - loss: 0.7034 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0107 - val_loss: 1.3404 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.6456\n",
      "Epoch 3/100\n",
      "3000/3000 [==============================] - 2s 588us/step - loss: 0.7032 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0106 - val_loss: 1.3577 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.6627\n",
      "Epoch 4/100\n",
      "3000/3000 [==============================] - 1s 499us/step - loss: 0.7031 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0105 - val_loss: 1.3769 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.6821\n",
      "Epoch 5/100\n",
      "3000/3000 [==============================] - 2s 544us/step - loss: 0.7031 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0104 - val_loss: 1.3960 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.7007\n",
      "Epoch 6/100\n",
      "3000/3000 [==============================] - 2s 540us/step - loss: 0.7030 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0103 - val_loss: 1.4088 - val_y_hat_prime_loss: 0.6956 - val_y_hat_loss: 0.7132\n",
      "Epoch 7/100\n",
      "3000/3000 [==============================] - 2s 569us/step - loss: 0.7030 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0103 - val_loss: 1.4195 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.7243\n",
      "Epoch 8/100\n",
      "3000/3000 [==============================] - 2s 582us/step - loss: 0.7030 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0103 - val_loss: 1.4268 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.7320\n",
      "Epoch 9/100\n",
      "3000/3000 [==============================] - 2s 565us/step - loss: 0.7031 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0102 - val_loss: 1.4449 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.7499\n",
      "Epoch 10/100\n",
      "3000/3000 [==============================] - 2s 543us/step - loss: 0.7029 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.4555 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.7606\n",
      "Epoch 11/100\n",
      "3000/3000 [==============================] - 2s 562us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.4732 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.7783\n",
      "Epoch 12/100\n",
      "3000/3000 [==============================] - 2s 593us/step - loss: 0.7027 - y_hat_prime_loss: 0.6925 - y_hat_loss: 0.0102 - val_loss: 1.4796 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.7843\n",
      "Epoch 13/100\n",
      "3000/3000 [==============================] - 2s 536us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.5019 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.8068\n",
      "Epoch 14/100\n",
      "3000/3000 [==============================] - 2s 543us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5083 - val_y_hat_prime_loss: 0.6955 - val_y_hat_loss: 0.8128\n",
      "Epoch 15/100\n",
      "3000/3000 [==============================] - 2s 535us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5061 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.8113\n",
      "Epoch 16/100\n",
      "3000/3000 [==============================] - 2s 577us/step - loss: 0.7029 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.5160 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.8206\n",
      "Epoch 17/100\n",
      "3000/3000 [==============================] - 2s 546us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5253 - val_y_hat_prime_loss: 0.6957 - val_y_hat_loss: 0.8296\n",
      "Epoch 18/100\n",
      "3000/3000 [==============================] - 2s 556us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.5327 - val_y_hat_prime_loss: 0.6956 - val_y_hat_loss: 0.8371\n",
      "Epoch 19/100\n",
      "3000/3000 [==============================] - 2s 550us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5389 - val_y_hat_prime_loss: 0.6959 - val_y_hat_loss: 0.8430\n",
      "Epoch 20/100\n",
      "3000/3000 [==============================] - 2s 540us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5441 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.8490\n",
      "Epoch 21/100\n",
      "3000/3000 [==============================] - 2s 524us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5510 - val_y_hat_prime_loss: 0.6947 - val_y_hat_loss: 0.8563\n",
      "Epoch 22/100\n",
      "3000/3000 [==============================] - 2s 538us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5555 - val_y_hat_prime_loss: 0.6958 - val_y_hat_loss: 0.8597\n",
      "Epoch 23/100\n",
      "3000/3000 [==============================] - 2s 517us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5567 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.8618\n",
      "Epoch 24/100\n",
      "3000/3000 [==============================] - 2s 556us/step - loss: 0.7031 - y_hat_prime_loss: 0.6929 - y_hat_loss: 0.0102 - val_loss: 1.5628 - val_y_hat_prime_loss: 0.6943 - val_y_hat_loss: 0.8686\n",
      "Epoch 25/100\n",
      "3000/3000 [==============================] - 2s 563us/step - loss: 0.7029 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.5674 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.8724\n",
      "Epoch 26/100\n",
      "3000/3000 [==============================] - 2s 554us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5670 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.8716\n",
      "Epoch 27/100\n",
      "3000/3000 [==============================] - 2s 546us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5719 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.8765\n",
      "Epoch 28/100\n",
      "3000/3000 [==============================] - 2s 553us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.5759 - val_y_hat_prime_loss: 0.6947 - val_y_hat_loss: 0.8811\n",
      "Epoch 29/100\n",
      "3000/3000 [==============================] - 2s 539us/step - loss: 0.7030 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0103 - val_loss: 1.5853 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.8900\n",
      "Epoch 30/100\n",
      "3000/3000 [==============================] - 2s 539us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5783 - val_y_hat_prime_loss: 0.6956 - val_y_hat_loss: 0.8827\n",
      "Epoch 31/100\n",
      "3000/3000 [==============================] - 1s 469us/step - loss: 0.7029 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.5875 - val_y_hat_prime_loss: 0.6957 - val_y_hat_loss: 0.8918\n",
      "Epoch 32/100\n",
      "3000/3000 [==============================] - 2s 554us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5899 - val_y_hat_prime_loss: 0.6947 - val_y_hat_loss: 0.8952\n",
      "Epoch 33/100\n",
      "3000/3000 [==============================] - 2s 548us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5903 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.8955\n",
      "Epoch 34/100\n",
      "3000/3000 [==============================] - 2s 581us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5945 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.8995\n",
      "Epoch 35/100\n",
      "3000/3000 [==============================] - 2s 553us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5974 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.9026\n",
      "Epoch 36/100\n",
      "3000/3000 [==============================] - 2s 589us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5969 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.9018\n",
      "Epoch 37/100\n",
      "3000/3000 [==============================] - 2s 587us/step - loss: 0.7030 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.6106 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.9155\n",
      "Epoch 38/100\n",
      "3000/3000 [==============================] - 2s 528us/step - loss: 0.7031 - y_hat_prime_loss: 0.6929 - y_hat_loss: 0.0102 - val_loss: 1.6057 - val_y_hat_prime_loss: 0.6946 - val_y_hat_loss: 0.9111\n",
      "Epoch 39/100\n",
      "3000/3000 [==============================] - 2s 548us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6149 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.9196\n",
      "Epoch 40/100\n",
      "3000/3000 [==============================] - 2s 568us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.6130 - val_y_hat_prime_loss: 0.6959 - val_y_hat_loss: 0.9171\n",
      "Epoch 41/100\n",
      "3000/3000 [==============================] - 2s 555us/step - loss: 0.7029 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.6130 - val_y_hat_prime_loss: 0.6955 - val_y_hat_loss: 0.9175\n",
      "Epoch 42/100\n",
      "3000/3000 [==============================] - 2s 559us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6270 - val_y_hat_prime_loss: 0.6957 - val_y_hat_loss: 0.9313\n",
      "Epoch 43/100\n",
      "3000/3000 [==============================] - 2s 572us/step - loss: 0.7029 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0103 - val_loss: 1.6081 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.9133\n",
      "Epoch 44/100\n",
      "3000/3000 [==============================] - 2s 560us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6305 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.9355\n",
      "Epoch 45/100\n",
      "3000/3000 [==============================] - 2s 576us/step - loss: 0.7028 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.6267 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.9314\n",
      "Epoch 46/100\n",
      "3000/3000 [==============================] - 2s 515us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6325 - val_y_hat_prime_loss: 0.6957 - val_y_hat_loss: 0.9369\n",
      "Epoch 47/100\n",
      "3000/3000 [==============================] - 2s 572us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6382 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.9430\n",
      "Epoch 48/100\n",
      "3000/3000 [==============================] - 2s 538us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6332 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.9383\n",
      "Epoch 49/100\n",
      "3000/3000 [==============================] - 2s 545us/step - loss: 0.7026 - y_hat_prime_loss: 0.6925 - y_hat_loss: 0.0101 - val_loss: 1.6373 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.9420\n",
      "Epoch 50/100\n",
      "3000/3000 [==============================] - 2s 544us/step - loss: 0.7026 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0100 - val_loss: 1.6425 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.9475\n",
      "Epoch 51/100\n",
      "3000/3000 [==============================] - 2s 602us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.6494 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.9544\n",
      "Epoch 52/100\n",
      "3000/3000 [==============================] - 2s 572us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.6632 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.9684\n",
      "Epoch 53/100\n",
      "3000/3000 [==============================] - 2s 549us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6413 - val_y_hat_prime_loss: 0.6960 - val_y_hat_loss: 0.9452\n",
      "Epoch 54/100\n",
      "3000/3000 [==============================] - 2s 580us/step - loss: 0.7031 - y_hat_prime_loss: 0.6929 - y_hat_loss: 0.0103 - val_loss: 1.6398 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.9446\n",
      "Epoch 55/100\n",
      "3000/3000 [==============================] - 2s 552us/step - loss: 0.7030 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0103 - val_loss: 1.6424 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.9471\n",
      "Epoch 56/100\n",
      "3000/3000 [==============================] - 2s 564us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6443 - val_y_hat_prime_loss: 0.6955 - val_y_hat_loss: 0.9488\n",
      "Epoch 57/100\n",
      "3000/3000 [==============================] - 2s 562us/step - loss: 0.7026 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0100 - val_loss: 1.6492 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.9539\n",
      "Epoch 58/100\n",
      "3000/3000 [==============================] - 2s 554us/step - loss: 0.7029 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.6525 - val_y_hat_prime_loss: 0.6965 - val_y_hat_loss: 0.9560\n",
      "Epoch 59/100\n",
      "3000/3000 [==============================] - 2s 540us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6554 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.9601\n",
      "Epoch 60/100\n",
      "3000/3000 [==============================] - 2s 582us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6591 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.9639\n",
      "Epoch 61/100\n",
      "3000/3000 [==============================] - 2s 573us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6636 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.9684\n",
      "Epoch 62/100\n",
      "3000/3000 [==============================] - 2s 504us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6634 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.9681\n",
      "Epoch 63/100\n",
      "3000/3000 [==============================] - 2s 534us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6696 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.9745\n",
      "Epoch 64/100\n",
      "3000/3000 [==============================] - 2s 552us/step - loss: 0.7030 - y_hat_prime_loss: 0.6929 - y_hat_loss: 0.0101 - val_loss: 1.6613 - val_y_hat_prime_loss: 0.6959 - val_y_hat_loss: 0.9654\n",
      "Epoch 65/100\n",
      "3000/3000 [==============================] - 2s 529us/step - loss: 0.7029 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.6630 - val_y_hat_prime_loss: 0.6956 - val_y_hat_loss: 0.9674\n",
      "Epoch 66/100\n",
      "3000/3000 [==============================] - 2s 533us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6650 - val_y_hat_prime_loss: 0.6956 - val_y_hat_loss: 0.9693\n",
      "Epoch 67/100\n",
      "3000/3000 [==============================] - 2s 600us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6726 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.9776\n",
      "Epoch 68/100\n",
      "3000/3000 [==============================] - 2s 523us/step - loss: 0.7028 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.6629 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.9681\n",
      "Epoch 69/100\n",
      "3000/3000 [==============================] - 2s 520us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6646 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.9693\n",
      "Epoch 70/100\n",
      "3000/3000 [==============================] - 2s 566us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6686 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.9738\n",
      "Epoch 71/100\n",
      "3000/3000 [==============================] - 2s 533us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.7082 - val_y_hat_prime_loss: 0.6955 - val_y_hat_loss: 1.0127\n",
      "Epoch 72/100\n",
      "3000/3000 [==============================] - 2s 569us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0102 - val_loss: 1.6624 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.9670\n",
      "Epoch 73/100\n",
      "3000/3000 [==============================] - 2s 554us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6737 - val_y_hat_prime_loss: 0.6957 - val_y_hat_loss: 0.9780\n",
      "Epoch 74/100\n",
      "3000/3000 [==============================] - 2s 571us/step - loss: 0.7029 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6824 - val_y_hat_prime_loss: 0.6947 - val_y_hat_loss: 0.9877\n",
      "Epoch 75/100\n",
      "3000/3000 [==============================] - 2s 519us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6672 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.9724\n",
      "Epoch 76/100\n",
      "3000/3000 [==============================] - 2s 533us/step - loss: 0.7028 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6705 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.9754\n",
      "Epoch 77/100\n",
      "3000/3000 [==============================] - 2s 550us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.6703 - val_y_hat_prime_loss: 0.6960 - val_y_hat_loss: 0.9743\n",
      "Epoch 78/100\n",
      "3000/3000 [==============================] - 2s 536us/step - loss: 1.5932 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.9005 - val_loss: 2.2282 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 1.5328\n",
      "Epoch 79/100\n",
      "3000/3000 [==============================] - 2s 558us/step - loss: 0.7859 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0934 - val_loss: 1.5243 - val_y_hat_prime_loss: 0.6956 - val_y_hat_loss: 0.8288\n",
      "Epoch 80/100\n",
      "3000/3000 [==============================] - 1s 483us/step - loss: 0.7328 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0402 - val_loss: 1.3849 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.6896\n",
      "Epoch 81/100\n",
      "3000/3000 [==============================] - 2s 567us/step - loss: 0.7081 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0154 - val_loss: 1.3989 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.7040\n",
      "Epoch 82/100\n",
      "3000/3000 [==============================] - 2s 533us/step - loss: 0.7041 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0114 - val_loss: 1.4495 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.7543\n",
      "Epoch 83/100\n",
      "3000/3000 [==============================] - 2s 536us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0102 - val_loss: 1.4887 - val_y_hat_prime_loss: 0.6951 - val_y_hat_loss: 0.7936\n",
      "Epoch 84/100\n",
      "3000/3000 [==============================] - 2s 561us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5236 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.8283\n",
      "Epoch 85/100\n",
      "3000/3000 [==============================] - 2s 583us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5517 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 0.8563\n",
      "Epoch 86/100\n",
      "3000/3000 [==============================] - 2s 537us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.5729 - val_y_hat_prime_loss: 0.6950 - val_y_hat_loss: 0.8779\n",
      "Epoch 87/100\n",
      "3000/3000 [==============================] - 2s 544us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.5892 - val_y_hat_prime_loss: 0.6947 - val_y_hat_loss: 0.8945\n",
      "Epoch 88/100\n",
      "3000/3000 [==============================] - 2s 520us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0100 - val_loss: 1.6047 - val_y_hat_prime_loss: 0.6948 - val_y_hat_loss: 0.9099\n",
      "Epoch 89/100\n",
      "3000/3000 [==============================] - 2s 574us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6163 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.9214\n",
      "Epoch 90/100\n",
      "3000/3000 [==============================] - 2s 568us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6285 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 0.9333\n",
      "Epoch 91/100\n",
      "3000/3000 [==============================] - 2s 576us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6492 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 0.9537\n",
      "Epoch 92/100\n",
      "3000/3000 [==============================] - 2s 555us/step - loss: 0.7027 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.6593 - val_y_hat_prime_loss: 0.6958 - val_y_hat_loss: 0.9636\n",
      "Epoch 93/100\n",
      "3000/3000 [==============================] - 2s 515us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.6634 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.9685\n",
      "Epoch 94/100\n",
      "3000/3000 [==============================] - 2s 511us/step - loss: 0.7029 - y_hat_prime_loss: 0.6928 - y_hat_loss: 0.0101 - val_loss: 1.6696 - val_y_hat_prime_loss: 0.6955 - val_y_hat_loss: 0.9741\n",
      "Epoch 95/100\n",
      "3000/3000 [==============================] - 2s 560us/step - loss: 0.7026 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0100 - val_loss: 1.6793 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.9844\n",
      "Epoch 96/100\n",
      "3000/3000 [==============================] - 2s 584us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0100 - val_loss: 1.6948 - val_y_hat_prime_loss: 0.6949 - val_y_hat_loss: 0.9999\n",
      "Epoch 97/100\n",
      "3000/3000 [==============================] - 2s 535us/step - loss: 0.7026 - y_hat_prime_loss: 0.6925 - y_hat_loss: 0.0101 - val_loss: 1.7107 - val_y_hat_prime_loss: 0.6952 - val_y_hat_loss: 1.0155\n",
      "Epoch 98/100\n",
      "3000/3000 [==============================] - 1s 489us/step - loss: 0.7028 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.7104 - val_y_hat_prime_loss: 0.6953 - val_y_hat_loss: 1.0151\n",
      "Epoch 99/100\n",
      "3000/3000 [==============================] - 2s 540us/step - loss: 0.7026 - y_hat_prime_loss: 0.6926 - y_hat_loss: 0.0101 - val_loss: 1.7174 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 1.0221\n",
      "Epoch 100/100\n",
      "3000/3000 [==============================] - 2s 552us/step - loss: 0.7027 - y_hat_prime_loss: 0.6927 - y_hat_loss: 0.0101 - val_loss: 1.7226 - val_y_hat_prime_loss: 0.6954 - val_y_hat_loss: 1.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febea6064a8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(twitter, epochs=100, validation_split=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse gradient layer from https://github.com/michetonu/gradient_reversal_keras_tf/blob/master/flipGradientTF.py\n",
    "# Added compute_output_shape for Keras 2 compatibility\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "def reverse_gradient(X, hp_lambda):\n",
    "    '''Flips the sign of the incoming gradient during training.'''\n",
    "    try:\n",
    "        reverse_gradient.num_calls += 1\n",
    "    except AttributeError:\n",
    "        reverse_gradient.num_calls = 1\n",
    "\n",
    "    grad_name = \"GradientReversal%d\" % reverse_gradient.num_calls\n",
    "\n",
    "    @tf.RegisterGradient(grad_name)\n",
    "    def _flip_gradients(op, grad):\n",
    "        return [tf.negative(grad) * hp_lambda]\n",
    "\n",
    "    g = K.get_session().graph\n",
    "    with g.gradient_override_map({'Identity': grad_name}):\n",
    "        y = tf.identity(X)\n",
    "\n",
    "    return y\n",
    "\n",
    "class GradientReversal(Layer):\n",
    "    '''Flip the sign of gradient during training.'''\n",
    "    def __init__(self, hp_lambda, **kwargs):\n",
    "        super(GradientReversal, self).__init__(**kwargs)\n",
    "        self.supports_masking = False\n",
    "        self.hp_lambda = hp_lambda\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return reverse_gradient(x, self.hp_lambda)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'hp_lambda': self.hp_lambda}\n",
    "        base_config = super(GradientReversal, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A_BOW:\n",
    "    def __init__(self, x_dim, xl=100, tl=50, cl=50, inv_factor=1):\n",
    "        self.x_dim = x_dim\n",
    "        self.xl = xl\n",
    "        self.tl = tl\n",
    "        self.cl = cl\n",
    "        self.inv_factor = inv_factor\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        x_input = Input((self.x_dim,), name=\"x_input\")\n",
    "        e = Dense(self.xl, activation=\"relu\", name=\"e\")(x_input)\n",
    "    \n",
    "        l = Dense(self.tl, activation=\"relu\")(e)\n",
    "        t = Dense(2, activation=\"softmax\", name=\"y\")(l)\n",
    "        \n",
    "        l = GradientReversal(self.inv_factor)(e)\n",
    "        l = Dense(self.cl, activation=\"relu\")(l)\n",
    "        c = Dense(2, activation=\"softmax\", name=\"z\")(l)\n",
    "        \n",
    "        self.model = Model(x_input, [t, c])\n",
    "        self.model.compile(optimizer=\"adam\",\n",
    "                           loss=[\"categorical_crossentropy\", \"categorical_crossentropy\"],)\n",
    "#                            loss_weights=[1, -1 * self.inv_factor])\n",
    "        \n",
    "    def fit(self, d, *args, **kwargs):\n",
    "        tocat = lambda x: to_categorical(x, num_classes=2)\n",
    "        vd = kwargs.get(\"validation_data\", ())\n",
    "        if type(vd) != tuple:\n",
    "            kwargs[\"validation_data\"] = (vd.X, [tocat(vd.y), tocat(vd.z)])\n",
    "        cbs = kwargs.get(\"callbacks\", [])\n",
    "        if \"Metrics\" not in [cb.__class__.__qualname__ for cb in cbs]:\n",
    "            cbs.append(metrics)\n",
    "            kwargs[\"callbacks\"] = cbs\n",
    "        return self.model.fit(d.X, [tocat(d.y), tocat(d.z)], *args, **kwargs)\n",
    "    \n",
    "    def predict(self, d, *args, **kwargs):\n",
    "        return self.model.predict(d.X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = A_BOW(twitter.features.size, xl=50, tl=10, cl=10,\n",
    "          inv_factor=.5)\n",
    "kvu.plot_model(m.model, 'ABOW.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 7.3953 - y_loss: 0.5260 - z_loss: 6.8692\n",
      "val_f1_y: 0.6551\n",
      "val_f1_z: 0.0268 z_pred: #1: 14 / count: 1000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 7.3505 - y_loss: 0.5178 - z_loss: 6.8327 - val_loss: 6.5324 - val_y_loss: 0.9879 - val_z_loss: 5.5445\n",
      "Epoch 2/100\n",
      " 930/1000 [==========================>...] - ETA: 0s - loss: 5.0178 - y_loss: 0.1884 - z_loss: 4.8295\n",
      "val_f1_y: 0.1491\n",
      "val_f1_z: 0.6746 z_pred: #1: 1000 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.2310 - y_loss: 0.1984 - z_loss: 5.0327 - val_loss: 10.0568 - val_y_loss: 3.0222 - val_z_loss: 7.0346\n",
      "Epoch 3/100\n",
      " 930/1000 [==========================>...] - ETA: 0s - loss: 4.3636 - y_loss: 0.1277 - z_loss: 4.2359\n",
      "val_f1_y: 0.6908\n",
      "val_f1_z: 0.3976 z_pred: #1: 638 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 4.4441 - y_loss: 0.1376 - z_loss: 4.3065 - val_loss: 6.8847 - val_y_loss: 0.8017 - val_z_loss: 6.0831\n",
      "Epoch 4/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 5.7680 - y_loss: 0.1080 - z_loss: 5.6600\n",
      "val_f1_y: 0.4483\n",
      "val_f1_z: 0.1487 z_pred: #1: 298 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.7605 - y_loss: 0.1173 - z_loss: 5.6432 - val_loss: 6.4026 - val_y_loss: 1.3119 - val_z_loss: 5.0907\n",
      "Epoch 5/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.9734 - y_loss: 0.1388 - z_loss: 1.8345\n",
      "val_f1_y: 0.6691\n",
      "val_f1_z: 0.5425 z_pred: #1: 280 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.9488 - y_loss: 0.1377 - z_loss: 1.8111 - val_loss: 4.4015 - val_y_loss: 2.7903 - val_z_loss: 1.6113\n",
      "Epoch 6/100\n",
      " 930/1000 [==========================>...] - ETA: 0s - loss: 0.7780 - y_loss: 0.1320 - z_loss: 0.6459\n",
      "val_f1_y: 0.5907\n",
      "val_f1_z: 0.6120 z_pred: #1: 478 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8043 - y_loss: 0.1305 - z_loss: 0.6738 - val_loss: 3.4326 - val_y_loss: 1.8427 - val_z_loss: 1.5899\n",
      "Epoch 7/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.0672 - y_loss: 0.0660 - z_loss: 1.0012\n",
      "val_f1_y: 0.6454\n",
      "val_f1_z: 0.5901 z_pred: #1: 396 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0818 - y_loss: 0.0689 - z_loss: 1.0128 - val_loss: 3.3031 - val_y_loss: 1.6042 - val_z_loss: 1.6989\n",
      "Epoch 8/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.1114 - y_loss: 0.0441 - z_loss: 1.0673\n",
      "val_f1_y: 0.6355\n",
      "val_f1_z: 0.5397 z_pred: #1: 373 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1135 - y_loss: 0.0429 - z_loss: 1.0705 - val_loss: 2.8961 - val_y_loss: 1.3592 - val_z_loss: 1.5369\n",
      "Epoch 9/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 1.1565 - y_loss: 0.1345 - z_loss: 1.0220\n",
      "val_f1_y: 0.6713\n",
      "val_f1_z: 0.3536 z_pred: #1: 164 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1683 - y_loss: 0.1363 - z_loss: 1.0320 - val_loss: 6.4896 - val_y_loss: 4.4447 - val_z_loss: 2.0448\n",
      "Epoch 10/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.7468 - y_loss: 0.0746 - z_loss: 0.6722\n",
      "val_f1_y: 0.6687\n",
      "val_f1_z: 0.6300 z_pred: #1: 564 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7496 - y_loss: 0.0733 - z_loss: 0.6763 - val_loss: 2.5366 - val_y_loss: 1.5697 - val_z_loss: 0.9670\n",
      "Epoch 11/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 0.9823 - y_loss: 0.0537 - z_loss: 0.9286\n",
      "val_f1_y: 0.7162\n",
      "val_f1_z: 0.4249 z_pred: #1: 263 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9615 - y_loss: 0.0532 - z_loss: 0.9082 - val_loss: 3.7053 - val_y_loss: 2.1505 - val_z_loss: 1.5548\n",
      "Epoch 12/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 1.3002 - y_loss: 0.2756 - z_loss: 1.0247\n",
      "val_f1_y: 0.4305\n",
      "val_f1_z: 0.6747 z_pred: #1: 988 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2948 - y_loss: 0.2676 - z_loss: 1.0272 - val_loss: 5.7014 - val_y_loss: 3.1408 - val_z_loss: 2.5606\n",
      "Epoch 13/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.8083 - y_loss: 0.3619 - z_loss: 1.4465\n",
      "val_f1_y: 0.6438\n",
      "val_f1_z: 0.5457 z_pred: #1: 389 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.7402 - y_loss: 0.3525 - z_loss: 1.3877 - val_loss: 4.0092 - val_y_loss: 2.6401 - val_z_loss: 1.3691\n",
      "Epoch 14/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.1131 - y_loss: 0.1085 - z_loss: 1.0046\n",
      "val_f1_y: 0.4795\n",
      "val_f1_z: 0.5854 z_pred: #1: 492 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0938 - y_loss: 0.1041 - z_loss: 0.9897 - val_loss: 4.3854 - val_y_loss: 3.1536 - val_z_loss: 1.2318\n",
      "Epoch 15/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 1.0591 - y_loss: 0.0855 - z_loss: 0.9736\n",
      "val_f1_y: 0.6839\n",
      "val_f1_z: 0.6601 z_pred: #1: 803 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0407 - y_loss: 0.0834 - z_loss: 0.9573 - val_loss: 3.4007 - val_y_loss: 1.7809 - val_z_loss: 1.6198\n",
      "Epoch 16/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.1454 - y_loss: 0.0768 - z_loss: 1.0686\n",
      "val_f1_y: 0.6240\n",
      "val_f1_z: 0.6283 z_pred: #1: 516 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1397 - y_loss: 0.0753 - z_loss: 1.0644 - val_loss: 3.4218 - val_y_loss: 2.1740 - val_z_loss: 1.2478\n",
      "Epoch 17/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 1.1064 - y_loss: 0.0373 - z_loss: 1.0691\n",
      "val_f1_y: 0.7190\n",
      "val_f1_z: 0.6052 z_pred: #1: 598 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1228 - y_loss: 0.0410 - z_loss: 1.0818 - val_loss: 3.0170 - val_y_loss: 1.6948 - val_z_loss: 1.3222\n",
      "Epoch 18/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.3898 - y_loss: 0.0837 - z_loss: 1.3061\n",
      "val_f1_y: 0.7511\n",
      "val_f1_z: 0.1680 z_pred: #1: 98 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3707 - y_loss: 0.0816 - z_loss: 1.2891 - val_loss: 5.1640 - val_y_loss: 1.9344 - val_z_loss: 3.2296\n",
      "Epoch 19/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.3424 - y_loss: 0.1564 - z_loss: 1.1860\n",
      "val_f1_y: 0.7741\n",
      "val_f1_z: 0.6384 z_pred: #1: 810 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3428 - y_loss: 0.1537 - z_loss: 1.1891 - val_loss: 3.5637 - val_y_loss: 1.5551 - val_z_loss: 2.0086\n",
      "Epoch 20/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.1224 - y_loss: 0.0460 - z_loss: 1.0764\n",
      "val_f1_y: 0.7389\n",
      "val_f1_z: 0.1393 z_pred: #1: 94 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1297 - y_loss: 0.0451 - z_loss: 1.0846 - val_loss: 3.9510 - val_y_loss: 1.5242 - val_z_loss: 2.4267\n",
      "Epoch 21/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.9602 - y_loss: 0.0595 - z_loss: 0.9007\n",
      "val_f1_y: 0.7824\n",
      "val_f1_z: 0.1599 z_pred: #1: 79 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9404 - y_loss: 0.0602 - z_loss: 0.8802 - val_loss: 3.2309 - val_y_loss: 1.4747 - val_z_loss: 1.7562\n",
      "Epoch 22/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.7932 - y_loss: 0.0693 - z_loss: 0.7238\n",
      "val_f1_y: 0.4251\n",
      "val_f1_z: 0.6501 z_pred: #1: 780 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7819 - y_loss: 0.0681 - z_loss: 0.7138 - val_loss: 4.9194 - val_y_loss: 3.8235 - val_z_loss: 1.0958\n",
      "Epoch 23/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.8854 - y_loss: 0.0472 - z_loss: 0.8382\n",
      "val_f1_y: 0.7225\n",
      "val_f1_z: 0.5412 z_pred: #1: 548 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8676 - y_loss: 0.0454 - z_loss: 0.8222 - val_loss: 2.8267 - val_y_loss: 1.8571 - val_z_loss: 0.9696\n",
      "Epoch 24/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.8179 - y_loss: 0.0360 - z_loss: 0.7818\n",
      "val_f1_y: 0.7033\n",
      "val_f1_z: 0.5059 z_pred: #1: 428 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8147 - y_loss: 0.0348 - z_loss: 0.7799 - val_loss: 2.7306 - val_y_loss: 1.8899 - val_z_loss: 0.8407\n",
      "Epoch 25/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.6804 - y_loss: 0.0216 - z_loss: 0.6588\n",
      "val_f1_y: 0.7342\n",
      "val_f1_z: 0.4000 z_pred: #1: 286 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6910 - y_loss: 0.0210 - z_loss: 0.6701 - val_loss: 2.4683 - val_y_loss: 1.6007 - val_z_loss: 0.8676\n",
      "Epoch 26/100\n",
      " 920/1000 [==========================>...] - ETA: 0s - loss: 0.8755 - y_loss: 0.0249 - z_loss: 0.8507\n",
      "val_f1_y: 0.7685\n",
      "val_f1_z: 0.2486 z_pred: #1: 191 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8591 - y_loss: 0.0233 - z_loss: 0.8359 - val_loss: 2.6241 - val_y_loss: 1.4620 - val_z_loss: 1.1621\n",
      "Epoch 27/100\n",
      " 920/1000 [==========================>...] - ETA: 0s - loss: 0.9293 - y_loss: 0.0307 - z_loss: 0.8986\n",
      "val_f1_y: 0.7790\n",
      "val_f1_z: 0.6119 z_pred: #1: 890 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9360 - y_loss: 0.0286 - z_loss: 0.9074 - val_loss: 2.4499 - val_y_loss: 1.3558 - val_z_loss: 1.0941\n",
      "Epoch 28/100\n",
      " 920/1000 [==========================>...] - ETA: 0s - loss: 0.8356 - y_loss: 0.0226 - z_loss: 0.8129\n",
      "val_f1_y: 0.8043\n",
      "val_f1_z: 0.4009 z_pred: #1: 399 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8531 - y_loss: 0.0245 - z_loss: 0.8286 - val_loss: 2.2403 - val_y_loss: 1.3513 - val_z_loss: 0.8890\n",
      "Epoch 29/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.8620 - y_loss: 0.0760 - z_loss: 0.7860\n",
      "val_f1_y: 0.7602\n",
      "val_f1_z: 0.6571 z_pred: #1: 952 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8574 - y_loss: 0.0722 - z_loss: 0.7852 - val_loss: 2.2815 - val_y_loss: 1.3976 - val_z_loss: 0.8839\n",
      "Epoch 30/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 0.9892 - y_loss: 0.0381 - z_loss: 0.9511\n",
      "val_f1_y: 0.7792\n",
      "val_f1_z: 0.3026 z_pred: #1: 218 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9993 - y_loss: 0.0533 - z_loss: 0.9460 - val_loss: 3.2600 - val_y_loss: 2.1155 - val_z_loss: 1.1445\n",
      "Epoch 31/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.8979 - y_loss: 0.0727 - z_loss: 0.8252\n",
      "val_f1_y: 0.7888\n",
      "val_f1_z: 0.4708 z_pred: #1: 400 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9017 - y_loss: 0.0720 - z_loss: 0.8297 - val_loss: 2.3973 - val_y_loss: 1.4992 - val_z_loss: 0.8981\n",
      "Epoch 32/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.6415 - y_loss: 0.0276 - z_loss: 0.6139\n",
      "val_f1_y: 0.7953\n",
      "val_f1_z: 0.5964 z_pred: #1: 658 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6406 - y_loss: 0.0268 - z_loss: 0.6138 - val_loss: 2.4977 - val_y_loss: 1.6835 - val_z_loss: 0.8142\n",
      "Epoch 33/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.9082 - y_loss: 0.0216 - z_loss: 0.8866\n",
      "val_f1_y: 0.8085\n",
      "val_f1_z: 0.2460 z_pred: #1: 361 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9133 - y_loss: 0.0208 - z_loss: 0.8925 - val_loss: 2.6786 - val_y_loss: 1.3068 - val_z_loss: 1.3718\n",
      "Epoch 34/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.2950 - y_loss: 0.0355 - z_loss: 1.2596\n",
      "val_f1_y: 0.7764\n",
      "val_f1_z: 0.6746 z_pred: #1: 1000 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.3077 - y_loss: 0.0351 - z_loss: 1.2726 - val_loss: 3.4678 - val_y_loss: 1.3155 - val_z_loss: 2.1523\n",
      "Epoch 35/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.9399 - y_loss: 0.1063 - z_loss: 0.8336\n",
      "val_f1_y: 0.6209\n",
      "val_f1_z: 0.4288 z_pred: #1: 242 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9665 - y_loss: 0.1074 - z_loss: 0.8591 - val_loss: 3.7664 - val_y_loss: 2.4703 - val_z_loss: 1.2961\n",
      "Epoch 36/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.8484 - y_loss: 0.0301 - z_loss: 0.8184\n",
      "val_f1_y: 0.7773\n",
      "val_f1_z: 0.4788 z_pred: #1: 339 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8529 - y_loss: 0.0292 - z_loss: 0.8237 - val_loss: 3.2548 - val_y_loss: 1.9527 - val_z_loss: 1.3021\n",
      "Epoch 37/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 1.3397 - y_loss: 0.0978 - z_loss: 1.2419\n",
      "val_f1_y: 0.7449\n",
      "val_f1_z: 0.6513 z_pred: #1: 876 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3569 - y_loss: 0.0948 - z_loss: 1.2621 - val_loss: 3.3849 - val_y_loss: 2.0542 - val_z_loss: 1.3307\n",
      "Epoch 38/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.3119 - y_loss: 0.0975 - z_loss: 1.2144\n",
      "val_f1_y: 0.6197\n",
      "val_f1_z: 0.5115 z_pred: #1: 449 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.3247 - y_loss: 0.0926 - z_loss: 1.2321 - val_loss: 4.2334 - val_y_loss: 2.9648 - val_z_loss: 1.2686\n",
      "Epoch 39/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 1.5553 - y_loss: 0.0730 - z_loss: 1.4823\n",
      "val_f1_y: 0.6154\n",
      "val_f1_z: 0.4367 z_pred: #1: 462 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5269 - y_loss: 0.0799 - z_loss: 1.4471 - val_loss: 4.4587 - val_y_loss: 3.0181 - val_z_loss: 1.4406\n",
      "Epoch 40/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 1.2940 - y_loss: 0.0157 - z_loss: 1.2783\n",
      "val_f1_y: 0.7517\n",
      "val_f1_z: 0.0957 z_pred: #1: 55 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3197 - y_loss: 0.0158 - z_loss: 1.3039 - val_loss: 4.6609 - val_y_loss: 2.2708 - val_z_loss: 2.3901\n",
      "Epoch 41/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.8586 - y_loss: 0.0152 - z_loss: 0.8434\n",
      "val_f1_y: 0.7757\n",
      "val_f1_z: 0.4879 z_pred: #1: 524 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8619 - y_loss: 0.0229 - z_loss: 0.8391 - val_loss: 2.8922 - val_y_loss: 1.9642 - val_z_loss: 0.9280\n",
      "Epoch 42/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.0083 - y_loss: 0.1023 - z_loss: 0.9059\n",
      "val_f1_y: 0.4641\n",
      "val_f1_z: 0.4678 z_pred: #1: 564 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0078 - y_loss: 0.1072 - z_loss: 0.9007 - val_loss: 4.9747 - val_y_loss: 3.8993 - val_z_loss: 1.0755\n",
      "Epoch 43/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 2.8198 - y_loss: 0.0514 - z_loss: 2.7684\n",
      "val_f1_y: 0.6758\n",
      "val_f1_z: 0.5506 z_pred: #1: 668 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.9141 - y_loss: 0.0499 - z_loss: 2.8642 - val_loss: 5.5865 - val_y_loss: 2.9862 - val_z_loss: 2.6003\n",
      "Epoch 44/100\n",
      " 930/1000 [==========================>...] - ETA: 0s - loss: 5.6528 - y_loss: 0.0205 - z_loss: 5.6323\n",
      "val_f1_y: 0.6873\n",
      "val_f1_z: 0.3609 z_pred: #1: 616 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.5148 - y_loss: 0.0302 - z_loss: 5.4847 - val_loss: 7.6450 - val_y_loss: 3.3357 - val_z_loss: 4.3093\n",
      "Epoch 45/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 2.7790 - y_loss: 0.0195 - z_loss: 2.7595\n",
      "val_f1_y: 0.7831\n",
      "val_f1_z: 0.4930 z_pred: #1: 769 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 2.7815 - y_loss: 0.0192 - z_loss: 2.7624 - val_loss: 5.2768 - val_y_loss: 1.7430 - val_z_loss: 3.5338\n",
      "Epoch 46/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.3460 - y_loss: 0.0564 - z_loss: 1.2896\n",
      "val_f1_y: 0.7233\n",
      "val_f1_z: 0.2222 z_pred: #1: 256 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3421 - y_loss: 0.0553 - z_loss: 1.2868 - val_loss: 4.5328 - val_y_loss: 1.5310 - val_z_loss: 3.0018\n",
      "Epoch 47/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.5995 - y_loss: 0.0690 - z_loss: 1.5304\n",
      "val_f1_y: 0.6801\n",
      "val_f1_z: 0.5954 z_pred: #1: 744 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5749 - y_loss: 0.0677 - z_loss: 1.5072 - val_loss: 5.3400 - val_y_loss: 2.1000 - val_z_loss: 3.2399\n",
      "Epoch 48/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.8648 - y_loss: 0.1340 - z_loss: 1.7308\n",
      "val_f1_y: 0.7215\n",
      "val_f1_z: 0.6178 z_pred: #1: 692 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.8530 - y_loss: 0.1441 - z_loss: 1.7090 - val_loss: 5.4164 - val_y_loss: 2.4852 - val_z_loss: 2.9311\n",
      "Epoch 49/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.8523 - y_loss: 0.0581 - z_loss: 1.7942\n",
      "val_f1_y: 0.7367\n",
      "val_f1_z: 0.4038 z_pred: #1: 432 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.8676 - y_loss: 0.0575 - z_loss: 1.8101 - val_loss: 5.4697 - val_y_loss: 3.0934 - val_z_loss: 2.3763\n",
      "Epoch 50/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.6015 - y_loss: 0.0246 - z_loss: 1.5770\n",
      "val_f1_y: 0.5028\n",
      "val_f1_z: 0.4736 z_pred: #1: 589 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5917 - y_loss: 0.0243 - z_loss: 1.5673 - val_loss: 5.5738 - val_y_loss: 3.4071 - val_z_loss: 2.1667\n",
      "Epoch 51/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 1.5874 - y_loss: 0.0773 - z_loss: 1.5102\n",
      "val_f1_y: 0.6750\n",
      "val_f1_z: 0.6185 z_pred: #1: 904 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5511 - y_loss: 0.0727 - z_loss: 1.4784 - val_loss: 5.8987 - val_y_loss: 2.5255 - val_z_loss: 3.3732\n",
      "Epoch 52/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.3877 - y_loss: 0.0065 - z_loss: 1.3811\n",
      "val_f1_y: 0.7623\n",
      "val_f1_z: 0.3646 z_pred: #1: 440 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3742 - y_loss: 0.0065 - z_loss: 1.3677 - val_loss: 4.1749 - val_y_loss: 2.2339 - val_z_loss: 1.9410\n",
      "Epoch 53/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.3851 - y_loss: 0.0088 - z_loss: 1.3762\n",
      "val_f1_y: 0.7554\n",
      "val_f1_z: 0.6215 z_pred: #1: 833 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.3539 - y_loss: 0.0096 - z_loss: 1.3443 - val_loss: 3.5736 - val_y_loss: 2.1491 - val_z_loss: 1.4245\n",
      "Epoch 54/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.8996 - y_loss: 0.0390 - z_loss: 0.8606\n",
      "val_f1_y: 0.7585\n",
      "val_f1_z: 0.5548 z_pred: #1: 486 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8904 - y_loss: 0.0379 - z_loss: 0.8525 - val_loss: 3.1023 - val_y_loss: 2.2200 - val_z_loss: 0.8823\n",
      "Epoch 55/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.0191 - y_loss: 0.0470 - z_loss: 0.9721\n",
      "val_f1_y: 0.7446\n",
      "val_f1_z: 0.6516 z_pred: #1: 909 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0190 - y_loss: 0.0504 - z_loss: 0.9686 - val_loss: 4.3846 - val_y_loss: 3.0497 - val_z_loss: 1.3350\n",
      "Epoch 56/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.8057 - y_loss: 0.0290 - z_loss: 0.7767\n",
      "val_f1_y: 0.7471\n",
      "val_f1_z: 0.6537 z_pred: #1: 727 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8028 - y_loss: 0.0284 - z_loss: 0.7743 - val_loss: 3.4406 - val_y_loss: 2.6124 - val_z_loss: 0.8282\n",
      "Epoch 57/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.8076 - y_loss: 0.0482 - z_loss: 0.7594\n",
      "val_f1_y: 0.7362\n",
      "val_f1_z: 0.3564 z_pred: #1: 198 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7979 - y_loss: 0.0468 - z_loss: 0.7512 - val_loss: 3.4142 - val_y_loss: 2.4314 - val_z_loss: 0.9828\n",
      "Epoch 58/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.6964 - y_loss: 0.0184 - z_loss: 0.6780\n",
      "val_f1_y: 0.6497\n",
      "val_f1_z: 0.3352 z_pred: #1: 404 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7032 - y_loss: 0.0180 - z_loss: 0.6851 - val_loss: 3.7724 - val_y_loss: 2.6788 - val_z_loss: 1.0936\n",
      "Epoch 59/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.7054 - y_loss: 0.0045 - z_loss: 0.7009\n",
      "val_f1_y: 0.7522\n",
      "val_f1_z: 0.6827 z_pred: #1: 698 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7099 - y_loss: 0.0044 - z_loss: 0.7055 - val_loss: 3.1106 - val_y_loss: 2.3362 - val_z_loss: 0.7743\n",
      "Epoch 60/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.7353 - y_loss: 0.0049 - z_loss: 0.7304\n",
      "val_f1_y: 0.7064\n",
      "val_f1_z: 0.1749 z_pred: #1: 97 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7277 - y_loss: 0.0047 - z_loss: 0.7230 - val_loss: 3.7383 - val_y_loss: 2.4586 - val_z_loss: 1.2797\n",
      "Epoch 61/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.9832 - y_loss: 0.0027 - z_loss: 0.9805\n",
      "val_f1_y: 0.7421\n",
      "val_f1_z: 0.5453 z_pred: #1: 826 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9802 - y_loss: 0.0033 - z_loss: 0.9770 - val_loss: 3.4143 - val_y_loss: 2.2485 - val_z_loss: 1.1659\n",
      "Epoch 62/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.0043 - y_loss: 0.0026 - z_loss: 1.0016\n",
      "val_f1_y: 0.7579\n",
      "val_f1_z: 0.1526 z_pred: #1: 133 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0097 - y_loss: 0.0033 - z_loss: 1.0064 - val_loss: 3.1867 - val_y_loss: 2.0348 - val_z_loss: 1.1519\n",
      "Epoch 63/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.1620 - y_loss: 0.0037 - z_loss: 1.1583\n",
      "val_f1_y: 0.7801\n",
      "val_f1_z: 0.2208 z_pred: #1: 406 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1475 - y_loss: 0.0036 - z_loss: 1.1438 - val_loss: 2.9464 - val_y_loss: 1.7161 - val_z_loss: 1.2302\n",
      "Epoch 64/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.9900 - y_loss: 0.0184 - z_loss: 0.9716\n",
      "val_f1_y: 0.7380\n",
      "val_f1_z: 0.0619 z_pred: #1: 40 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0010 - y_loss: 0.0350 - z_loss: 0.9660 - val_loss: 5.6552 - val_y_loss: 3.7767 - val_z_loss: 1.8786\n",
      "Epoch 65/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.8907 - y_loss: 0.0935 - z_loss: 0.7972\n",
      "val_f1_y: 0.7743\n",
      "val_f1_z: 0.4243 z_pred: #1: 264 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8772 - y_loss: 0.0897 - z_loss: 0.7875 - val_loss: 2.8067 - val_y_loss: 2.0738 - val_z_loss: 0.7329\n",
      "Epoch 66/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.6069 - y_loss: 0.0035 - z_loss: 0.6033\n",
      "val_f1_y: 0.7833\n",
      "val_f1_z: 0.5018 z_pred: #1: 332 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5980 - y_loss: 0.0033 - z_loss: 0.5946 - val_loss: 2.6780 - val_y_loss: 1.9742 - val_z_loss: 0.7038\n",
      "Epoch 67/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.7494 - y_loss: 0.0034 - z_loss: 0.7460\n",
      "val_f1_y: 0.7917\n",
      "val_f1_z: 0.0890 z_pred: #1: 53 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7432 - y_loss: 0.0033 - z_loss: 0.7399 - val_loss: 3.2579 - val_y_loss: 1.8526 - val_z_loss: 1.4053\n",
      "Epoch 68/100\n",
      " 920/1000 [==========================>...] - ETA: 0s - loss: 0.8756 - y_loss: 0.0035 - z_loss: 0.8721\n",
      "val_f1_y: 0.8047\n",
      "val_f1_z: 0.6373 z_pred: #1: 944 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8950 - y_loss: 0.0034 - z_loss: 0.8916 - val_loss: 3.0684 - val_y_loss: 1.7162 - val_z_loss: 1.3523\n",
      "Epoch 69/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.9591 - y_loss: 0.0040 - z_loss: 0.9552\n",
      "val_f1_y: 0.8143\n",
      "val_f1_z: 0.0851 z_pred: #1: 55 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9617 - y_loss: 0.0039 - z_loss: 0.9578 - val_loss: 3.1040 - val_y_loss: 1.6011 - val_z_loss: 1.5029\n",
      "Epoch 70/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.1198 - y_loss: 0.0542 - z_loss: 1.0656\n",
      "val_f1_y: 0.7964\n",
      "val_f1_z: 0.6563 z_pred: #1: 975 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1220 - y_loss: 0.0544 - z_loss: 1.0676 - val_loss: 3.5257 - val_y_loss: 2.1492 - val_z_loss: 1.3764\n",
      "Epoch 71/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.8749 - y_loss: 0.0040 - z_loss: 0.8710\n",
      "val_f1_y: 0.8008\n",
      "val_f1_z: 0.4008 z_pred: #1: 554 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8757 - y_loss: 0.0039 - z_loss: 0.8718 - val_loss: 2.5795 - val_y_loss: 1.7108 - val_z_loss: 0.8687\n",
      "Epoch 72/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.7629 - y_loss: 0.0115 - z_loss: 0.7514\n",
      "val_f1_y: 0.7564\n",
      "val_f1_z: 0.1308 z_pred: #1: 72 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7552 - y_loss: 0.0113 - z_loss: 0.7439 - val_loss: 2.9236 - val_y_loss: 1.8088 - val_z_loss: 1.1149\n",
      "Epoch 73/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.7414 - y_loss: 0.0374 - z_loss: 0.7040\n",
      "val_f1_y: 0.7857\n",
      "val_f1_z: 0.1561 z_pred: #1: 93 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7426 - y_loss: 0.0403 - z_loss: 0.7023 - val_loss: 3.0309 - val_y_loss: 2.0627 - val_z_loss: 0.9682\n",
      "Epoch 74/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.8622 - y_loss: 0.0233 - z_loss: 0.8390\n",
      "val_f1_y: 0.7719\n",
      "val_f1_z: 0.6724 z_pred: #1: 990 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8596 - y_loss: 0.0226 - z_loss: 0.8370 - val_loss: 2.9185 - val_y_loss: 1.7558 - val_z_loss: 1.1627\n",
      "Epoch 75/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.9374 - y_loss: 0.0184 - z_loss: 0.9191\n",
      "val_f1_y: 0.7844\n",
      "val_f1_z: 0.0903 z_pred: #1: 45 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9390 - y_loss: 0.0184 - z_loss: 0.9205 - val_loss: 3.5564 - val_y_loss: 1.9554 - val_z_loss: 1.6011\n",
      "Epoch 76/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.8605 - y_loss: 0.1257 - z_loss: 0.7348\n",
      "val_f1_y: 0.5860\n",
      "val_f1_z: 0.6334 z_pred: #1: 874 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8569 - y_loss: 0.1239 - z_loss: 0.7330 - val_loss: 3.9610 - val_y_loss: 3.1130 - val_z_loss: 0.8480\n",
      "Epoch 77/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 0.8807 - y_loss: 0.2210 - z_loss: 0.6596\n",
      "val_f1_y: 0.7431\n",
      "val_f1_z: 0.6737 z_pred: #1: 999 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0052 - y_loss: 0.2902 - z_loss: 0.7150 - val_loss: 4.1215 - val_y_loss: 2.5353 - val_z_loss: 1.5862\n",
      "Epoch 78/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.2599 - y_loss: 0.4110 - z_loss: 0.8490\n",
      "val_f1_y: 0.6972\n",
      "val_f1_z: 0.6080 z_pred: #1: 820 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2275 - y_loss: 0.3904 - z_loss: 0.8370 - val_loss: 4.0429 - val_y_loss: 2.9416 - val_z_loss: 1.1014\n",
      "Epoch 79/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.7005 - y_loss: 0.0025 - z_loss: 0.6980\n",
      "val_f1_y: 0.7179\n",
      "val_f1_z: 0.6729 z_pred: #1: 995 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7103 - y_loss: 0.0031 - z_loss: 0.7072 - val_loss: 4.2307 - val_y_loss: 2.7721 - val_z_loss: 1.4586\n",
      "Epoch 80/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.7339 - y_loss: 0.0030 - z_loss: 0.7309\n",
      "val_f1_y: 0.7230\n",
      "val_f1_z: 0.1860 z_pred: #1: 190 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7315 - y_loss: 0.0030 - z_loss: 0.7286 - val_loss: 3.8253 - val_y_loss: 2.6114 - val_z_loss: 1.2138\n",
      "Epoch 81/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.9940 - y_loss: 0.0031 - z_loss: 0.9910\n",
      "val_f1_y: 0.7476\n",
      "val_f1_z: 0.5212 z_pred: #1: 788 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9938 - y_loss: 0.0030 - z_loss: 0.9908 - val_loss: 3.5016 - val_y_loss: 2.4374 - val_z_loss: 1.0642\n",
      "Epoch 82/100\n",
      " 930/1000 [==========================>...] - ETA: 0s - loss: 1.0411 - y_loss: 0.0033 - z_loss: 1.0378\n",
      "val_f1_y: 0.7677\n",
      "val_f1_z: 0.0980 z_pred: #1: 185 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0299 - y_loss: 0.0030 - z_loss: 1.0268 - val_loss: 3.5281 - val_y_loss: 2.2973 - val_z_loss: 1.2307\n",
      "Epoch 83/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.7798 - y_loss: 0.0058 - z_loss: 0.7740\n",
      "val_f1_y: 0.7391\n",
      "val_f1_z: 0.3971 z_pred: #1: 589 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7754 - y_loss: 0.0056 - z_loss: 0.7698 - val_loss: 3.0755 - val_y_loss: 2.2044 - val_z_loss: 0.8711\n",
      "Epoch 84/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.8745 - y_loss: 0.0034 - z_loss: 0.8712\n",
      "val_f1_y: 0.7510\n",
      "val_f1_z: 0.6302 z_pred: #1: 897 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8664 - y_loss: 0.0033 - z_loss: 0.8630 - val_loss: 3.2466 - val_y_loss: 2.0995 - val_z_loss: 1.1470\n",
      "Epoch 85/100\n",
      " 940/1000 [===========================>..] - ETA: 0s - loss: 0.7759 - y_loss: 0.0028 - z_loss: 0.7731\n",
      "val_f1_y: 0.7683\n",
      "val_f1_z: 0.0680 z_pred: #1: 50 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7780 - y_loss: 0.0033 - z_loss: 0.7747 - val_loss: 3.0381 - val_y_loss: 2.0015 - val_z_loss: 1.0366\n",
      "Epoch 86/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 0.8494 - y_loss: 0.0032 - z_loss: 0.8462\n",
      "val_f1_y: 0.7818\n",
      "val_f1_z: 0.0077 z_pred: #1: 8 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8705 - y_loss: 0.0032 - z_loss: 0.8674 - val_loss: 3.4863 - val_y_loss: 1.9398 - val_z_loss: 1.5465\n",
      "Epoch 87/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.7453 - y_loss: 0.0036 - z_loss: 0.7417\n",
      "val_f1_y: 0.7814\n",
      "val_f1_z: 0.2278 z_pred: #1: 369 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7477 - y_loss: 0.0036 - z_loss: 0.7442 - val_loss: 2.7384 - val_y_loss: 1.8352 - val_z_loss: 0.9032\n",
      "Epoch 88/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.5333 - y_loss: 0.1054 - z_loss: 1.4278\n",
      "val_f1_y: 0.5943\n",
      "val_f1_z: 0.1890 z_pred: #1: 306 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.5103 - y_loss: 0.1031 - z_loss: 1.4073 - val_loss: 4.4431 - val_y_loss: 3.2946 - val_z_loss: 1.1484\n",
      "Epoch 89/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 1.0583 - y_loss: 0.0541 - z_loss: 1.0042\n",
      "val_f1_y: 0.7656\n",
      "val_f1_z: 0.2096 z_pred: #1: 264 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0521 - y_loss: 0.0536 - z_loss: 0.9985 - val_loss: 3.7719 - val_y_loss: 2.7958 - val_z_loss: 0.9761\n",
      "Epoch 90/100\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 1.1306 - y_loss: 0.0034 - z_loss: 1.1272\n",
      "val_f1_y: 0.7443\n",
      "val_f1_z: 0.0266 z_pred: #1: 17 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1248 - y_loss: 0.0033 - z_loss: 1.1215 - val_loss: 4.0096 - val_y_loss: 2.2753 - val_z_loss: 1.7343\n",
      "Epoch 91/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 0.7981 - y_loss: 0.0030 - z_loss: 0.7951\n",
      "val_f1_y: 0.7549\n",
      "val_f1_z: 0.0657 z_pred: #1: 39 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7966 - y_loss: 0.0029 - z_loss: 0.7937 - val_loss: 3.2936 - val_y_loss: 2.0972 - val_z_loss: 1.1964\n",
      "Epoch 92/100\n",
      " 920/1000 [==========================>...] - ETA: 0s - loss: 0.7149 - y_loss: 0.0032 - z_loss: 0.7116\n",
      "val_f1_y: 0.7624\n",
      "val_f1_z: 0.6676 z_pred: #1: 989 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7439 - y_loss: 0.0030 - z_loss: 0.7409 - val_loss: 3.0752 - val_y_loss: 1.9855 - val_z_loss: 1.0897\n",
      "Epoch 93/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.9975 - y_loss: 0.0031 - z_loss: 0.9944\n",
      "val_f1_y: 0.7890\n",
      "val_f1_z: 0.2121 z_pred: #1: 236 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9843 - y_loss: 0.0030 - z_loss: 0.9813 - val_loss: 2.8342 - val_y_loss: 1.8676 - val_z_loss: 0.9667\n",
      "Epoch 94/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.9860 - y_loss: 0.0032 - z_loss: 0.9828\n",
      "val_f1_y: 0.7972\n",
      "val_f1_z: 0.0479 z_pred: #1: 34 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0146 - y_loss: 0.0031 - z_loss: 1.0114 - val_loss: 3.6274 - val_y_loss: 1.7765 - val_z_loss: 1.8509\n",
      "Epoch 95/100\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 1.0565 - y_loss: 0.0542 - z_loss: 1.0023\n",
      "val_f1_y: 0.7651\n",
      "val_f1_z: 0.0647 z_pred: #1: 109 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0327 - y_loss: 0.0515 - z_loss: 0.9812 - val_loss: 3.0616 - val_y_loss: 1.9673 - val_z_loss: 1.0943\n",
      "Epoch 96/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 1.0818 - y_loss: 0.1605 - z_loss: 0.9213\n",
      "val_f1_y: 0.7389\n",
      "val_f1_z: 0.0039 z_pred: #1: 9 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0571 - y_loss: 0.1542 - z_loss: 0.9029 - val_loss: 5.4594 - val_y_loss: 3.4254 - val_z_loss: 2.0340\n",
      "Epoch 97/100\n",
      " 970/1000 [============================>.] - ETA: 0s - loss: 1.0089 - y_loss: 0.0956 - z_loss: 0.9133\n",
      "val_f1_y: 0.7704\n",
      "val_f1_z: 0.1665 z_pred: #1: 272 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0164 - y_loss: 0.0927 - z_loss: 0.9237 - val_loss: 3.9822 - val_y_loss: 2.8211 - val_z_loss: 1.1611\n",
      "Epoch 98/100\n",
      " 920/1000 [==========================>...] - ETA: 0s - loss: 0.8534 - y_loss: 0.0295 - z_loss: 0.8239\n",
      "val_f1_y: 0.6573\n",
      "val_f1_z: 0.1913 z_pred: #1: 254 / count: 1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8406 - y_loss: 0.0272 - z_loss: 0.8134 - val_loss: 3.7477 - val_y_loss: 2.9013 - val_z_loss: 0.8463\n",
      "Epoch 99/100\n",
      " 960/1000 [===========================>..] - ETA: 0s - loss: 0.8850 - y_loss: 0.0226 - z_loss: 0.8624\n",
      "val_f1_y: 0.7209\n",
      "val_f1_z: 0.0754 z_pred: #1: 101 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8836 - y_loss: 0.0217 - z_loss: 0.8619 - val_loss: 3.6944 - val_y_loss: 2.6169 - val_z_loss: 1.0776\n",
      "Epoch 100/100\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.8224 - y_loss: 0.0722 - z_loss: 0.7501\n",
      "val_f1_y: 0.7267\n",
      "val_f1_z: 0.5300 z_pred: #1: 706 / count: 1000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8261 - y_loss: 0.0715 - z_loss: 0.7546 - val_loss: 3.5655 - val_y_loss: 2.6733 - val_z_loss: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febd00a2940>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(twitter.biased_datasets[0], epochs=100, batch_size=10, validation_data=twitter.biased_datasets[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
